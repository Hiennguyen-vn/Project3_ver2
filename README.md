# Domain-Adaptive Selection for Constrained Multitask Evolutionary Optimization

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

> **Cáº£i tiáº¿n thuáº­t toÃ¡n RL-CMTEA thÃ´ng qua cÆ¡ cháº¿ Domain-Adaptive Selection (DaS) cho Knowledge Transfer**

---

## ğŸ“‹ TÃ³m táº¯t (Abstract)

Repository nÃ y trÃ¬nh bÃ y má»™t cáº£i tiáº¿n quan trá»ng cho thuáº­t toÃ¡n **RL-CMTEA** (Reinforcement Learning - Constrained Multitask Evolutionary Algorithm) thÃ´ng qua viá»‡c tÃ­ch há»£p cÆ¡ cháº¿ **Domain-Adaptive Selection (DaS)** vÃ o quÃ¡ trÃ¬nh Knowledge Transfer (KT).

**Váº¥n Ä‘á» nghiÃªn cá»©u:** Thuáº­t toÃ¡n RL-CMTEA gá»‘c sá»­ dá»¥ng random block selection Ä‘á»ƒ chuyá»ƒn tri thá»©c giá»¯a cÃ¡c tÃ¡c vá»¥, dáº«n Ä‘áº¿n nguy cÆ¡ **Negative Transfer** - viá»‡c truyá»n thÃ´ng tin khÃ´ng liÃªn quan hoáº·c cÃ³ háº¡i giá»¯a cÃ¡c tÃ¡c vá»¥.

**Giáº£i phÃ¡p Ä‘á» xuáº¥t:** DaS-KT thay tháº¿ cÆ¡ cháº¿ ngáº«u nhiÃªn báº±ng má»™t há»‡ thá»‘ng há»c trá»ng sá»‘ thÃ­ch nghi, cho phÃ©p thuáº­t toÃ¡n tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  Æ°u tiÃªn cÃ¡c chiá»u khÃ´ng gian (dimensions) cÃ³ lá»£i cho viá»‡c truyá»n tri thá»©c.

**Káº¿t quáº£ thá»±c nghiá»‡m:** TrÃªn bá»™ benchmark CMT1-CMT9 (30 independent runs, 200K FES), DaS-KT Ä‘áº¡t Ä‘Æ°á»£c:
- **83% win rate** (15/18 tasks) so vá»›i thuáº­t toÃ¡n gá»‘c
- Cáº£i thiá»‡n Ä‘á»™t phÃ¡ trÃªn cÃ¡c bÃ i toÃ¡n khÃ³: CMT7 T1 (~30Ã—), CMT4 T1 (~10Ã—)
- Äáº¡t global optimum trÃªn nhiá»u bÃ i toÃ¡n (CMT2-T2, CMT6-T2)

---

## ğŸ¯ Äá»™ng lá»±c nghiÃªn cá»©u (Motivation)

### Váº¥n Ä‘á» cá»§a Random Knowledge Transfer

Trong thuáº­t toÃ¡n RL-CMTEA gá»‘c, Knowledge Transfer Ä‘Æ°á»£c thá»±c hiá»‡n qua hai bÆ°á»›c:
1. **K-means clustering** (`divK`): NhÃ³m cÃ¡c cÃ¡ thá»ƒ tÆ°Æ¡ng Ä‘á»“ng
2. **Random block selection** (`divD`): Chá»n ngáº«u nhiÃªn cÃ¡c chiá»u Ä‘á»ƒ truyá»n

CÆ¡ cháº¿ nÃ y cÃ³ hai háº¡n cháº¿ chÃ­nh:

**1. Negative Transfer:**
```
Task 1: f(xâ‚, xâ‚‚, ..., xâ‚â‚€â‚€) - Chá»‰ cÃ³ xâ‚, xâ‚…, xâ‚‡ liÃªn quan Ä‘áº¿n optimum
Task 2: g(xâ‚, xâ‚‚, ..., xâ‚â‚€â‚€) - Chá»‰ cÃ³ xâ‚‚, xâ‚…, xâ‚‰ liÃªn quan Ä‘áº¿n optimum

Random KT cÃ³ thá»ƒ truyá»n xâ‚ƒâ‚„, xâ‚‡â‚ˆ (nhiá»…u) â†’ PhÃ¡ vá»¡ cáº¥u trÃºc tá»‘t Ä‘ang hÃ¬nh thÃ nh
```

**2. KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c cáº¥u trÃºc tÆ°Æ¡ng Ä‘á»“ng:**
- CÃ¡c tÃ¡c vá»¥ thÆ°á»ng cÃ³ má»™t sá»‘ chiá»u chung quan trá»ng (vÃ­ dá»¥: xâ‚… á»Ÿ trÃªn)
- Random selection khÃ´ng há»c Ä‘Æ°á»£c pattern nÃ y qua cÃ¡c tháº¿ há»‡

### Táº¡i sao DaS giáº£i quyáº¿t Ä‘Æ°á»£c?

DaS hoáº¡t Ä‘á»™ng nhÆ° má»™t **Structure Learning Mechanism**:
- Há»c ma tráº­n trá»ng sá»‘ $W_{srcâ†’dst}$ cho má»—i cáº·p tÃ¡c vá»¥
- Chiá»u nÃ o giÃºp sinh ra cÃ¡ thá»ƒ con tá»‘t â†’ TÄƒng trá»ng sá»‘
- Chiá»u nÃ o gÃ¢y nhiá»…u â†’ Giáº£m trá»ng sá»‘
- Káº¿t quáº£: Chá»‰ truyá»n "tri thá»©c tinh tÃºy", loáº¡i bá» nhiá»…u

---

## ğŸ”¬ PhÆ°Æ¡ng phÃ¡p (Methodology)

### 1. Kiáº¿n trÃºc tá»•ng quan

```
RL-CMTEA Core (Preserved)
â”œâ”€â”€ Dual Population (Main + Auxiliary)
â”œâ”€â”€ Q-Learning for Operator Selection
â”œâ”€â”€ Feasibility Priority + Îµ-constraint
â””â”€â”€ Knowledge Transfer â† [DaS INTEGRATION HERE]
```

**NguyÃªn táº¯c thiáº¿t káº¿:** Chá»‰ thay Ä‘á»•i dimension selection trong KT, giá»¯ nguyÃªn toÃ n bá»™ cÃ¡c thÃ nh pháº§n khÃ¡c cá»§a RL-CMTEA.

### 2. DaS-KT Algorithm

#### BÆ°á»›c 1: Khá»Ÿi táº¡o ma tráº­n trá»ng sá»‘
```python
W[src, dst, i] = 1.0  # Uniform initialization
# W âˆˆ â„^(KÃ—KÃ—D) where K = sá»‘ task, D = sá»‘ chiá»u
```

#### BÆ°á»›c 2: Adaptive Dimension Selection
```python
# Chuáº©n hÃ³a trá»ng sá»‘ thÃ nh phÃ¢n phá»‘i xÃ¡c suáº¥t
p[i] = W[src, dst, i] / Î£ W[src, dst, j]

# Sampling without replacement
selected_dims = sample(p, size=divD, replace=False)
```

#### BÆ°á»›c 3: Knowledge Transfer & Evaluation
```python
offspring = KT(parent, selected_dims)  # Crossover trÃªn cÃ¡c chiá»u Ä‘Ã£ chá»n
fitness_offspring = evaluate(offspring)
```

#### BÆ°á»›c 4: Reward Computation
```python
# Reward dá»±a trÃªn Feasibility Priority ranking
if offspring better than worst_parent:
    R = improvement_rate  # Positive reward
else:
    R = -penalty  # Negative reward
```

#### BÆ°á»›c 5: Weight Update (Exponential Multiplicative Weights)
```python
for dim in selected_dims:
    W[src, dst, dim] *= exp(Î· * R)
    
# Normalize to prevent overflow
W[src, dst] = clip(W[src, dst], min=1e-10, max=1e10)
W[src, dst] /= sum(W[src, dst])
```

**Tham sá»‘:**
- Learning rate: `Î· = 0.05`
- Warmup period: `10 generations` (Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u ban Ä‘áº§u)

### 3. PhÃ¢n tÃ­ch lÃ½ thuyáº¿t: Táº¡i sao DaS hoáº¡t Ä‘á»™ng?

#### Äá»‹nh lÃ½ 1: Convergence to Optimal Dimensions (Informal)
Vá»›i giáº£ thiáº¿t ráº±ng tá»“n táº¡i má»™t táº­p con chiá»u $D^* \subset \{1, ..., D\}$ mÃ  viá»‡c truyá»n chÃºng luÃ´n cho káº¿t quáº£ tá»‘t hÆ¡n, thÃ¬:

$$\lim_{t \to \infty} P(\text{select } i | i \in D^*) \to 1$$

**Chá»©ng minh trá»±c quan:**
- CÃ¡c chiá»u trong $D^*$ nháº­n Ä‘Æ°á»£c reward dÆ°Æ¡ng liÃªn tá»¥c
- Theo cÃ´ng thá»©c $w_i \gets w_i \cdot \exp(\eta R)$, trá»ng sá»‘ cá»§a chÃºng tÄƒng mÅ©
- CÃ¡c chiá»u ngoÃ i $D^*$ cÃ³ reward Ã¢m hoáº·c 0 â†’ trá»ng sá»‘ giáº£m dáº§n
- Sau chuáº©n hÃ³a, xÃ¡c suáº¥t chá»n $D^*$ tiáº¿n vá» 1

#### Äá»‹nh lÃ½ 2: Robustness to Noise
DaS cÃ³ kháº£ nÄƒng chá»‘ng nhiá»…u tá»‘t hÆ¡n random selection vÃ¬:
- Random: $P(\text{select bad dim}) = \frac{|D \setminus D^*|}{D}$ (constant)
- DaS: $P(\text{select bad dim}) \propto \exp(-\eta \cdot t \cdot |R|)$ (exponential decay)

---

## ğŸ“Š Káº¿t quáº£ thá»±c nghiá»‡m (Experimental Results)

### Setup
- **Benchmark:** CMT1-CMT9 (Constrained Multitask Test Suite)
- **Runs:** 30 independent runs per problem
- **Budget:** 200,000 FES (Function Evaluations)
- **Comparison:** RL-CMTEA (Paper) vs RL-CMTEA + DaS (Ours)

### Tá»•ng quan káº¿t quáº£

![Performance Comparison](docs/comparison_cmt1_9_line.png)
*HÃ¬nh 1: So sÃ¡nh hiá»‡u nÄƒng trÃªn CMT1-CMT9. DaS (Ä‘Æ°á»ng xanh) tháº¯ng Ã¡p Ä‘áº£o trÃªn háº§u háº¿t cÃ¡c bÃ i toÃ¡n.*

### Báº£ng káº¿t quáº£ chi tiáº¿t (30-Run Mean)

| Problem | Task | Paper Mean | **DaS Mean** | Improvement | Status |
|---------|------|------------|--------------|-------------|--------|
| **CMT1** | T1 | 4.81e-17 | **3.70e-18** | ~10Ã— | âœ… Win |
| | T2 | **7.98e-14** | 0.199 | - | âŒ Loss* |
| **CMT2** | T1 | 2.19e-09 | **1.81e-10** | ~10Ã— | âœ… Win |
| | T2 | 5.92e-17 | **0.00** | Global Opt. | âœ… Win |
| **CMT3** | T1 | 2.28e-04 | **2.91e-08** | **~10â´Ã—** | âœ… Win |
| | T2 | 1.30e-03 | **6.36e-04** | +51% | âœ… Win |
| **CMT4** | T1 | 87.9 | **9.01** | **~10Ã—** | âœ… **Huge Win** |
| | T2 | 815 | **379** | +53.5% | âœ… Win |
| **CMT5** | T1 | **4.29e-12** | 0.648 | - | âŒ Loss* |
| | T2 | 97.4 | **48.8** | +49.8% | âœ… Win |
| **CMT6** | T1 | 1.79e-08 | **1.28e-13** | **~10âµÃ—** | âœ… Win |
| | T2 | 6.60e-05 | **~0** | Global Opt. | âœ… Win |
| **CMT7** | T1 | 11,300 | **369** | **~30Ã—** | âœ… **Huge Win** |
| | T2 | 129 | **62.2** | +51.8% | âœ… Win |
| **CMT8** | T1 | 16.1 | **6.00** | +62.7% | âœ… Win |
| | T2 | 91.9 | **43.1** | +53.1% | âœ… Win |
| **CMT9** | T1 | **19.4** | 8649 | - | âŒ Loss* |
| | T2 | 33,200 | **16,600** | +50.0% | âœ… Win |

**Tá»•ng káº¿t:** 15/18 tasks tháº¯ng (83% win rate)

*Xem pháº§n "Failure Mode Analysis" Ä‘á»ƒ hiá»ƒu nguyÃªn nhÃ¢n

### PhÃ¢n tÃ­ch sÃ¢u: Táº¡i sao DaS tháº¯ng?

#### Case Study 1: CMT7 - VÆ°á»£t qua Local Optima Trap

CMT7 lÃ  bÃ i toÃ¡n cÃ³ fitness landscape cá»±c ká»³ phá»©c táº¡p vá»›i nhiá»u local optima sÃ¢u.

**Paper's Problem:**
- Random KT liÃªn tá»¥c "phÃ¡ vá»¡" cÃ¡c building blocks tá»‘t
- Quáº§n thá»ƒ bá»‹ káº¹t á»Ÿ local optimum vá»›i lá»—i ~11,300

**DaS's Solution:**
- Há»c Ä‘Æ°á»£c ráº±ng chá»‰ nÃªn truyá»n dimensions 1, 5, 7 (giáº£ sá»­)
- Báº£o toÃ n cáº¥u trÃºc gen tá»‘t â†’ Escape local optima
- Káº¿t quáº£: Lá»—i giáº£m xuá»‘ng ~369 (**~30Ã— improvement**)

![CMT7 Convergence](docs/convergence_CMT7.png)
*HÃ¬nh 2: ÄÆ°á»ng há»™i tá»¥ cá»§a CMT7. DaS (xanh) thoÃ¡t khá»i plateau mÃ  Paper bá»‹ káº¹t.*

#### Case Study 2: CMT4 - Structure Discovery

CMT4 cÃ³ constraint phá»©c táº¡p vá»›i strong variable interaction.

**Insight tá»« DaS:**
- Ma tráº­n trá»ng sá»‘ há»c Ä‘Æ°á»£c cho tháº¥y chá»‰ cÃ³ ~10/100 dimensions thá»±c sá»± quan trá»ng
- DaS táº­p trung vÃ o cÃ¡c dimensions nÃ y â†’ Giáº£m lá»—i tá»« 87.9 xuá»‘ng 9.01

![CMT4 Convergence](docs/convergence_CMT4.png)
*HÃ¬nh 3: CMT4 convergence. DaS há»™i tá»¥ nhanh hÆ¡n vÃ  sÃ¢u hÆ¡n.*

---

## âš ï¸ Failure Mode Analysis

DaS khÃ´ng pháº£i lÃ  "silver bullet". ChÃºng tÃ´i phÃ¢n tÃ­ch 3 trÆ°á»ng há»£p tháº¥t báº¡i:

### 1. CMT1-T2: Premature Convergence
**NguyÃªn nhÃ¢n:**
- Landscape quÃ¡ Ä‘Æ¡n giáº£n, khÃ´ng cáº§n structure learning
- Random KT hoáº¡t Ä‘á»™ng nhÆ° regularization (diversity maintenance)
- DaS há»™i tá»¥ quÃ¡ sá»›m vÃ o má»™t táº­p dimensions â†’ Máº¥t diversity

**BÃ i há»c:** DaS cáº§n thÃªm entropy regularization cho bÃ i toÃ¡n Ä‘Æ¡n giáº£n.

### 2. CMT5-T1: High Variance
**Quan sÃ¡t:**
- Mean: DaS kÃ©m (0.648 vs 4.29e-12)
- Best: DaS váº«n Ä‘áº¡t optimum (4.44e-16)

**NguyÃªn nhÃ¢n:**
- Má»™t sá»‘ runs há»c sai structure ban Ä‘áº§u â†’ Káº¿t quáº£ kÃ©m
- KÃ©o tá»¥t Mean nhÆ°ng Best váº«n tá»‘t

**BÃ i há»c:** Cáº§n cÆ¡ cháº¿ "reset" hoáº·c "exploration boost" khi phÃ¡t hiá»‡n stagnation.

### 3. CMT9-T1: Negative Bias
**NguyÃªn nhÃ¢n:**
- Weak inter-task similarity
- DaS "over-trust" historical rewards â†’ GÃ¡n trá»ng sá»‘ cao cho dimensions thá»±c táº¿ khÃ´ng tá»‘t

**BÃ i há»c:** Cáº§n weight decay hoáº·c forgetting mechanism.

---

## ğŸš€ HÆ°á»›ng phÃ¡t triá»ƒn (Future Work)

### DaS v2: Entropy-Regularized Adaptive Selection
```python
# ThÃªm entropy term vÃ o objective
H(W) = -Î£ W[i] * log(W[i])
W[i] â† W[i] * exp(Î· * R + Î» * âˆ‚H/âˆ‚W[i])
```
**Má»¥c tiÃªu:** Duy trÃ¬ diversity, kháº¯c phá»¥c premature convergence.

### DaS v3: Forgetting Mechanism
```python
# Weight decay theo thá»i gian
W[i] â† Î± * W[i] + (1-Î±) * 1.0  # Î± = 0.95
```
**Má»¥c tiÃªu:** Giáº£m negative bias trÃªn bÃ i toÃ¡n non-convex.

---

## ğŸ“ Cáº¥u trÃºc Repository

```
.
â”œâ”€â”€ RL_CMTEA_DaS_v2.py      # Main algorithm (DaS integrated)
â”œâ”€â”€ DaS_KT.py               # DaS module
â”œâ”€â”€ test_all_cmt_das.py     # Experiment script
â”œâ”€â”€ docs/                   # Figures and results
â”‚   â”œâ”€â”€ comparison_*.png
â”‚   â””â”€â”€ convergence_*.png
â””â”€â”€ README.md               # This file
```

---

## ğŸ“š TrÃ­ch dáº«n (Citation)

Náº¿u báº¡n sá»­ dá»¥ng code nÃ y trong nghiÃªn cá»©u, vui lÃ²ng trÃ­ch dáº«n:

```bibtex
@misc{das_rlcmtea2024,
  title={Domain-Adaptive Selection for Constrained Multitask Evolutionary Optimization},
  author={Your Name},
  year={2024},
  note={Research Implementation}
}
```

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Original RL-CMTEA algorithm from [Paper Reference]
- CMT benchmark suite
- Inspiration from Domain-Adaptive Selection literature
